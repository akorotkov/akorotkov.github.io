<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Pg | Alexander Korotkov's blog]]></title>
  <link href="http://akorotkov.github.io/blog/categories/pg/atom.xml" rel="self"/>
  <link href="http://akorotkov.github.io/"/>
  <updated>2016-09-29T16:22:58+03:00</updated>
  <id>http://akorotkov.github.io/</id>
  <author>
    <name><![CDATA[Alexander Korotkov]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[PostgreSQL 9.6 Release Is Approaching. Postgres Pro Has Contributed to It.]]></title>
    <link href="http://akorotkov.github.io/blog/2016/09/29/release-9-6/"/>
    <updated>2016-09-29T16:20:00+03:00</updated>
    <id>http://akorotkov.github.io/blog/2016/09/29/release-9-6</id>
    <content type="html"><![CDATA[<p><img class="no-border center 2x" src="/images/ppg-9.6.png" width="365" height="95"></p>

<p>New major release of PostgreSQL is approaching.  PostgreSQL 9.6 is expected to
be released later today.  This is a great release which provides to users
<a href="https://www.postgresql.org/docs/9.6/static/release-9-6.html">set of outstanding new features</a>.
I’m especially happy that Postgres Professional did substantial contribution
to this release.  In particular, full-text search for phrases and scalability
improvements are listed as major enhancements of this new PostgreSQL release.</p>

<p>The full list of Postgres Professional constributions including:</p>

<!--more-->

<ul>
  <li>
    <p>Improve the pg_stat_activity view’s information about what a process is waiting for (Amit Kapila, Ildus Kurbangaliev)</p>

    <p>Historically a process has only been shown as waiting if it was waiting for a heavyweight lock. Now waits for lightweight locks and buffer pins are also shown in pg_stat_activity. Also, the type of lock being waited for is now visible. These changes replace the waiting column with wait_event_type and wait_event.</p>

    <p>See <a href="/blog/2016/03/25/wait_monitoring_9_6/">blog post</a> for details.</p>
  </li>
  <li>
    <p>Fix the default text search parser to allow leading digits in email and host tokens (Artur Zakirov)</p>

    <p>In most cases this will result in few changes in the parsing of text. But if you have data where such addresses occur frequently, it may be worth rebuilding dependent tsvector columns and indexes so that addresses of this form will be found properly by text searches.</p>

    <p>See <a href="https://www.postgresql.org/message-id/flat/56CC9C9D.1050603%40postgrespro.ru">mailing list discussion</a> for details.</p>
  </li>
  <li>
    <p>Allow GIN index builds to make effective use of maintenance_work_mem settings larger than 1 GB (Robert Abraham, Teodor Sigaev)</p>

    <p>See <a href="https://www.postgresql.org/message-id/flat/CABQqHAWYXW%2BNzAYw4uG_FnbjrdEFyRaigLRkQ7AzAtS6AbHnfA%40mail.gmail.com">mailing list discussion</a> for details.</p>
  </li>
  <li>
    <p>Add pages deleted from a GIN index’s pending list to the free space map immediately (Jeff Janes, Teodor Sigaev)</p>

    <p>This reduces bloat if the table is not vacuumed often.</p>

    <p>See <a href="https://www.postgresql.org/message-id/flat/CAMkU%3D1xfE1MnGMkv655hB8jCs3PBTb4S5H%2BFnQv8kcmYzyeBDQ%40mail.gmail.com">mailing list discussion</a> for details.</p>
  </li>
  <li>
    <p>Improve handling of dead index tuples in GiST indexes (Anastasia Lubennikova)</p>

    <p>Dead index tuples are now marked as such when an index scan notices that the corresponding heap tuple is dead. When inserting tuples, marked-dead tuples will be removed if needed to make space on the page.</p>

    <p>See <a href="https://www.postgresql.org/message-id/flat/CAP4vRV6FcKVOpPxs_9L327FpTWz75Ly%3DJRUeY-W89amS19BzwQ%40mail.gmail.com">mailing list discussion</a>  for details.</p>
  </li>
  <li>
    <p>Add an SP-GiST operator class for type box (Alexander Lebedev)</p>

    <p>See <a href="https://www.postgresql.org/message-id/flat/56352972.9020608%40postgrespro.ru">mailing list discussion</a> for details.</p>
  </li>
  <li>
    <p>Replace shared-buffer header spinlocks with atomic operations to improve scalability (Alexander Korotkov, Andres Freund)</p>

    <p>See <a href="/blog/2016/05/09/scalability-towards-millions-tps/">blog post</a> for details.</p>
  </li>
  <li>
    <p>Partition the shared hash table freelist to reduce contention on multi-CPU-socket servers (Aleksander Alekseev)</p>

    <p>See <a href="https://www.postgresql.org/message-id/flat/20151211170001.78ded9d7@fujitsu">mailing list discussion</a> for details.</p>
  </li>
  <li>
    <p>Improve performance of resource owners with many tracked objects (Aleksander Alekseev)</p>

    <p>See <a href="https://www.postgresql.org/message-id/flat/20151204151504.5c7e4278@fujitsu">mailing list discussion</a> for details.</p>
  </li>
  <li>
    <p>When appropriate, postpone evaluation of SELECT output expressions until after an ORDER BY sort (Konstantin Knizhnik)</p>

    <p>This change ensures that volatile or expensive functions in the output list are executed in the order suggested by ORDER BY, and that they are not evaluated more times than required when there is a LIMIT clause. Previously, these properties held if the ordering was performed by an index scan or pre-merge-join sort, but not if it was performed by a top-level sort.</p>

    <p>See <a href="https://www.postgresql.org/message-id/flat/9879B786-E011-44A1-91B8-54649B84106D%40postgrespro.ru">mailing list discussion</a> for details.</p>
  </li>
  <li>
    <p>Add options to ALTER OPERATOR to allow changing the selectivity functions associated with an existing operator (Yury Zhuravlev)</p>

    <p>See <a href="https://www.postgresql.org/message-id/flat/3348985.V7xMLFDaJO%40dinodell">mailing list discussion</a> for details.</p>
  </li>
  <li>
    <p>Introduce CREATE ACCESS METHOD to allow extensions to create index access methods (Alexander Korotkov, Petr Jelínek)</p>

    <p>See <a href="http://www.pgcon.org/2016/schedule/attachments/421_engines.pdf">slides</a> for details.</p>
  </li>
  <li>
    <p>Improve full-text search to support searching for phrases, that is, lexemes appearing adjacent to each other in a specific order, or with a specified distance between them (Teodor Sigaev, Oleg Bartunov, Dmitry Ivanov)</p>

    <p>See <a href="http://www.pgcon.org/2016/schedule/attachments/436_pgcon-2016-fts.pdf">slides</a> for details.</p>
  </li>
  <li>
    <p>Allow omitting one or both boundaries in an array slice specifier, e.g. array_col[3:] (Yury Zhuravlev)</p>

    <p>See <a href="https://www.postgresql.org/message-id/flat/2987745.PueTkqGxbO@dinodell">mailing list discussion</a> for details.</p>
  </li>
  <li>
    <p>Upgrade the ispell dictionary type to handle modern Hunspell files and support more languages (Artur Zakirov)</p>

    <p>See <a href="https://www.postgresql.org/message-id/flat/56264908.2020203@postgrespro.ru">mailing list discussion</a> for details.</p>
  </li>
  <li>
    <p>Add new functions for tsvector data (Stas Kelvich)</p>

    <p>See <a href="https://www.postgresql.org/message-id/flat/DBD45805-968D-48B1-992A-79F8AC7D3140@postgrespro.ru">mailing list discussion</a> for details.</p>
  </li>
  <li>
    <p>Allow ts_stat() and tsvector_update_trigger() to operate on values that are of types binary-compatible with the expected argument type, not only that argument type; for example allow citext where text is expected (Teodor Sigaev)</p>

    <p>See <a href="https://www.postgresql.org/message-id/flat/EA8346F9-8F64-4837-ABE1-B383AF36E0DC@kineticode.com">mailing list discussion</a> for details.</p>
  </li>
  <li>
    <p>Improve pg_rewind so that it can work when the target timeline changes (Alexander Korotkov)</p>

    <p>This allows, for example, rewinding a promoted standby back to some state of the old master’s timeline.</p>

    <p>See <a href="https://www.postgresql.org/message-id/flat/CAPpHfdtaqYGz6JKvx4AdySA_ceqPH7Lki=F1HxUeNNaBRC7Mtw@mail.gmail.com">mailing list discussion</a> for details.</p>
  </li>
  <li>
    <p>Restructure index access method API to hide most of it at the C level (Alexander Korotkov, Andrew Gierth)</p>

    <p>This change modernizes the index AM API to look more like the designs we have adopted for foreign data wrappers and tablesample handlers. This simplifies the C code and makes it much more practical to define index access methods in installable extensions. A consequence is that most of the columns of the pg_am system catalog have disappeared. New inspection functions have been added to allow SQL queries to determine index AM properties that used to be discoverable from pg_am.</p>

    <p>See <a href="http://www.pgcon.org/2016/schedule/attachments/421_engines.pdf">slides</a> for details.</p>
  </li>
  <li>
    <p>Add a generic interface for writing WAL records (Alexander Korotkov, Petr Jelínek, Markus Nullmeier)</p>

    <p>This change allows extensions to write WAL records for changes to pages using a standard layout. The problem of needing to replay WAL without access to the extension is solved by having generic replay code. This allows extensions to implement, for example, index access methods and have WAL support for them.</p>

    <p>See <a href="http://www.pgcon.org/2016/schedule/attachments/421_engines.pdf">slides</a> for details.</p>
  </li>
  <li>
    <p>Allow SP-GiST operator classes to store an arbitrary “traversal value” while descending the index (Alexander Lebedev, Teodor Sigaev)</p>

    <p>This is somewhat like the “reconstructed value”, but it could be any arbitrary chunk of data, not necessarily of the same data type as the indexed column.</p>

    <p>See <a href="https://www.postgresql.org/message-id/flat/56352972.9020608%40postgrespro.ru">mailing list discussion</a> for details.</p>
  </li>
  <li>
    <p>Add contrib/bloom module that implements an index access method based on Bloom filtering (Teodor Sigaev, Alexander Korotkov)</p>

    <p>This is primarily a proof-of-concept for non-core index access methods, but it could be useful in its own right for queries that search many columns.</p>

    <p>See <a href="http://www.pgcon.org/2016/schedule/attachments/421_engines.pdf">slides</a> for details.</p>
  </li>
  <li>
    <p>In contrib/cube, introduce distance operators for cubes, and support kNN-style searches in GiST indexes on cube columns (Stas Kelvich)</p>

    <p>See <a href="https://www.postgresql.org/message-id/flat/9E07E159-E405-41E2-9889-A04F534FC257@gmail.com">mailing list discussion</a> for details.</p>
  </li>
  <li>
    <p>Add selectivity estimation functions for contrib/intarray operators to improve plans for queries using those operators (Yury Zhuravlev, Alexander Korotkov)</p>

    <p>See <a href="https://www.postgresql.org/message-id/flat/1529951.MrgHGDLjOD%40dinodell">mailing list discussion</a> for details.</p>
  </li>
  <li>
    <p>Make contrib/pageinspect’s heap_page_items() function show the raw data in each tuple, and add new functions tuple_data_split() and heap_page_item_attrs() for inspection of individual tuple fields (Nikolay Shaplov)</p>

    <p>See <a href="https://pgconf.ru/media/2016/05/13/tuple-internals.pdf">slides</a> for details.</p>
  </li>
  <li>
    <p>Add support for “word similarity” to contrib/pg_trgm (Alexander Korotkov, Artur Zakirov)</p>

    <p>These functions and operators measure the similarity between one string and the most similar single word of another string.</p>

    <p>See <a href="https://www.postgresql.org/message-id/flat/567461EC.4030803@postgrespro.ru#567461EC.4030803@postgrespro.ru">mailing list discussion</a> for details.</p>
  </li>
  <li>
    <p>Add configuration parameter pg_trgm.similarity_threshold for contrib/pg_trgm’s similarity threshold (Artur Zakirov)</p>

    <p>This threshold has always been configurable, but formerly it was controlled by special-purpose functions set_limit() and show_limit(). Those are now deprecated.</p>

    <p>See <a href="https://www.postgresql.org/message-id/flat/567461EC.4030803@postgrespro.ru#567461EC.4030803@postgrespro.ru">mailing list discussion</a> for details.</p>
  </li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Faceted Search in the Single PostgreSQL Query]]></title>
    <link href="http://akorotkov.github.io/blog/2016/06/17/faceted-search/"/>
    <updated>2016-06-17T14:20:00+03:00</updated>
    <id>http://akorotkov.github.io/blog/2016/06/17/faceted-search</id>
    <content type="html"><![CDATA[<p>Faceted search is very popular buzzword nowadays.  In short, faceted search
specialty is that its results are organized per category.  Popular search
engines are receiving special support of faceted search.</p>

<p>Let’s see what PostgreSQL can do in this field.  At first, let’s formalize our
task.  For each category which have matching documents we want to obtain:</p>

<ul>
  <li>Total number of matching documents;</li>
  <li>TOP N matching documents.</li>
</ul>

<p>For sure, it’s possible to query such data using multiple per category SQL
queries.  But we’ll make it in a single SQL query.  That also would be faster
in majority of cases.  The query below implements faceted search over
PostgreSQL mailing lists archives using window functions and CTE.  Usage
of window function is essential while CTE was used for better query readability.</p>

<!--more-->

<p><code>psql Faceted search SQL query
/*
 * Select all matching messages, calculate rank within list and total count
 * within list using window functions.
 */
WITH msg AS (
    SELECT
        message_id,
        subject,
        list,
        RANK() OVER (
            PARTITION BY list
            ORDER BY ts_rank_cd(body_tsvector,  plainto_tsquery('index bloat')), id
        ) rank,
        COUNT(*) OVER (PARTITION BY list) cnt
    FROM messages
    WHERE body_tsvector @@ plainto_tsquery('index bloat')
),
/* Aggregate messages and count per list into json. */
lst AS (
    SELECT
        list,
        jsonb_build_object(
            'count', cnt,
            'results', jsonb_agg(
                jsonb_build_object(
                    'message_id', message_id,
                    'subject', subject
        ))) AS data
    FROM msg
    WHERE rank &lt;= 5
    GROUP by list, cnt
)
/* Aggregate per list data into single json */
SELECT  jsonb_object_agg(list, data)
FROM    lst;
</code></p>

<p>The resulting JSON document contains total count of matching mailing list
messages and TOP 5 relevant messages for each list.</p>

<p><code>js Faceted search JSON result
{
  "pgsql-admin": {
    "count": 263,
    "results": [
      {"message_id": "CACjxUsMUWkY1Z2K2A6yVdF88GT3xcFw5ofWTR6r1zqLUYu0WzA@mail.gmail.com", "subject": "Re: Slow planning time"},
      {"message_id": "dcc563d11001041749w561874f7y6574fb42ab49f850@mail.gmail.com", "subject": "Re: Finetuning Autovacuum"},
      {"message_id": "AANLkTikWabMzCRCSWuNLuPizSSQX3YILgJrNZuzgp3yM@mail.gmail.com", "subject": "Re: blocking automatic vacuum"},
      {"message_id": "dcc563d10904011631l4058aabew12f3fe4895a072f3@mail.gmail.com", "subject": "Re: Vacuum Full"},
      {"message_id": "FE44E0D7EAD2ED4BB2165071DB8E328C03062D9D@egcrc-ex01.egcrc.org", "subject": "Re: postgres bogged down beyond tolerance"
      }
    ]
  },
/*................................................................................*/
  "pgsql-advocacy": {
    "count": 8,
    "results": [
      {"message_id": "Pine.LNX.4.33.0310291602220.22178-100000@css120.ihs.com", "subject": "Re: Press Release"},
      {"message_id": "20050502203626.GA29791@dcc.uchile.cl", "subject": "Re: [HACKERS] Increased company involvement"},
      {"message_id": "5d94f7afb26f56652e06ba0657573ef2@biglumber.com", "subject": "Search and archives still out of sync"},
      {"message_id": "Pine.GSO.4.64.0708010705100.13114@westnet.com", "subject": "Re: postgresql publication"},
      {"message_id": "20070801151739.GF6165@alvh.no-ip.org", "subject": "Re: postgresql publication"
      }
    ]
  }
}
</code></p>

<p>In the plan of this query we can see that <code>message_body_idx</code> GIN index is
scanned only once, and this is great.</p>

<p><code>psql Plan of faceted search SQL query
                                                                       QUERY PLAN
---------------------------------------------------------------------------------------------------------------------------------------------------
 Aggregate  (cost=2369.50..2369.51 rows=1 width=114) (actual time=34.232..34.232 rows=1 loops=1)
   CTE msg
     -&gt;  WindowAgg  (cost=2087.93..2354.30 rows=491 width=336) (actual time=30.925..33.087 rows=2486 loops=1)
           -&gt;  WindowAgg  (cost=2087.93..2222.96 rows=491 width=336) (actual time=30.716..32.020 rows=2486 loops=1)
                 -&gt;  Sort  (cost=2087.93..2089.16 rows=491 width=336) (actual time=30.711..30.838 rows=2486 loops=1)
                       Sort Key: messages.list, (ts_rank_cd(messages.body_tsvector, plainto_tsquery('index bloat'::text))), messages.id
                       Sort Method: quicksort  Memory: 582kB
                       -&gt;  Bitmap Heap Scan on messages  (cost=48.05..2065.98 rows=491 width=336) (actual time=3.037..24.345 rows=2486 loops=1)
                             Recheck Cond: (body_tsvector @@ plainto_tsquery('index bloat'::text))
                             Heap Blocks: exact=2044
                             -&gt;  Bitmap Index Scan on message_body_idx  (cost=0.00..47.93 rows=491 width=0) (actual time=2.723..2.723 rows=2486 loo
                                   Index Cond: (body_tsvector @@ plainto_tsquery('index bloat'::text))
   CTE lst
     -&gt;  HashAggregate  (cost=12.69..13.69 rows=67 width=540) (actual time=34.090..34.133 rows=14 loops=1)
           Group Key: msg.list, msg.cnt
           -&gt;  CTE Scan on msg  (cost=0.00..11.05 rows=164 width=540) (actual time=30.928..33.879 rows=68 loops=1)
                 Filter: (rank &lt;= 5)
                 Rows Removed by Filter: 2418
   -&gt;  CTE Scan on lst  (cost=0.00..1.34 rows=67 width=114) (actual time=34.092..34.140 rows=14 loops=1)
 Planning time: 0.380 ms
 Execution time: 34.357 ms
</code></p>

<p>Thus, it appears that nothing prevents you from implementing trendy kinds of
searches using old good SQL and powerful features of PostgreSQL including:
fulltext search, JSON support, window functions etc.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[RuntimeAppend in Pg_pathman: Achievements and New Challenges]]></title>
    <link href="http://akorotkov.github.io/blog/2016/06/15/pg_pathman-runtime-append/"/>
    <updated>2016-06-15T15:00:00+03:00</updated>
    <id>http://akorotkov.github.io/blog/2016/06/15/pg_pathman-runtime-append</id>
    <content type="html"><![CDATA[<p>Dealing with partitioned tables we can’t always select relevant partitions
during query planning.  Naturally, during query planning you can’t know values
which come from subquery or outer part of nested loop join.  Nevertheless, it
would be ridiculous to scan all the partitions in such cases.</p>

<p>This is why my Postgres Professional colleague Dmitry Ivanov developed a
new custom executor node for pg_pathman: RuntimeAppend.  This node behaves
like regular Append node: it contains set of children Nodes which should be
appended.  However, RuntimeAppend have one distinction: each run it selects
only relevant children to append basing on parameter values.</p>

<!--more-->

<p>Let’s consider example: join of <code>journal</code> table which contains row per each
30 seconds of year partitioned by day, and <code>q</code> table which refers 1000 random
rows of <code>journal</code> table.  Without RuntimeAppend optimizer selects Hash Join
plan.</p>

<p><code>sql Regular Append: Hash Join
# EXPLAIN ANALYZE SELECT * FROM q JOIN journal j ON q.dt = j.dt;
                                                          QUERY PLAN
-------------------------------------------------------------------------------------------------------------------------------
 Hash Join  (cost=27.50..25442.51 rows=1000 width=56) (actual time=0.479..252.506 rows=1000 loops=1)
   Hash Cond: (j.dt = q.dt)
   -&gt;  Append  (cost=0.00..21463.01 rows=1051201 width=49) (actual time=0.005..152.258 rows=1051201 loops=1)
         -&gt;  Seq Scan on journal_1 j  (cost=0.00..58.80 rows=2880 width=49) (actual time=0.004..0.247 rows=2880 loops=1)
         -&gt;  Seq Scan on journal_2 j_1  (cost=0.00..58.80 rows=2880 width=49) (actual time=0.001..0.208 rows=2880 loops=1)
         -&gt;  Seq Scan on journal_3 j_2  (cost=0.00..58.80 rows=2880 width=49) (actual time=0.001..0.197 rows=2880 loops=1)
...............................................................................................................................
         -&gt;  Seq Scan on journal_366 j_365  (cost=0.00..1.01 rows=1 width=49) (actual time=0.001..0.001 rows=1 loops=1)
   -&gt;  Hash  (cost=15.00..15.00 rows=1000 width=8) (actual time=0.185..0.185 rows=1000 loops=1)
         Buckets: 1024  Batches: 1  Memory Usage: 48kB
         -&gt;  Seq Scan on q  (cost=0.00..15.00 rows=1000 width=8) (actual time=0.003..0.074 rows=1000 loops=1)
 Planning time: 29.262 ms
 Execution time: 256.337 ms
(374 rows)
</code></p>

<p>The Hash Join execution takes 256 milliseconds for execution and 29 milliseconds
for planning.  Relatively high planning time is expected because all the
partitions are present in plan.  It’s surprising that optimizer didn’t select
Nested Loop join.  Let’s force it to do so by <code>enable_hashjoin = off</code> and
<code>enable_mergejoin = off</code>.</p>

<p><code>sql Regular Append: Nested Loop
# EXPLAIN ANALYZE SELECT * FROM q JOIN journal j ON q.dt = j.dt;
                                                                      QUERY PLAN
------------------------------------------------------------------------------------------------------------------------------------------------------
 Nested Loop  (cost=0.28..170817.00 rows=1000 width=56) (actual time=1.091..452.658 rows=1000 loops=1)
   -&gt;  Seq Scan on q  (cost=0.00..15.00 rows=1000 width=8) (actual time=0.006..0.158 rows=1000 loops=1)
   -&gt;  Append  (cost=0.28..167.14 rows=366 width=49) (actual time=0.218..0.438 rows=1 loops=1000)
         -&gt;  Index Scan using journal_1_dt_idx on journal_1 j  (cost=0.28..0.46 rows=1 width=49) (actual time=0.001..0.001 rows=0 loops=1000)
               Index Cond: (dt = q.dt)
         -&gt;  Index Scan using journal_2_dt_idx on journal_2 j_1  (cost=0.28..0.46 rows=1 width=49) (actual time=0.001..0.001 rows=0 loops=1000)
               Index Cond: (dt = q.dt)
         -&gt;  Index Scan using journal_3_dt_idx on journal_3 j_2  (cost=0.28..0.46 rows=1 width=49) (actual time=0.001..0.001 rows=0 loops=1000)
               Index Cond: (dt = q.dt)
......................................................................................................................................................
         -&gt;  Index Scan using journal_366_dt_idx on journal_366 j_365  (cost=0.12..0.15 rows=1 width=49) (actual time=0.001..0.001 rows=0 loops=1000)
               Index Cond: (dt = q.dt)
 Planning time: 29.922 ms
 Execution time: 456.140 ms
(737 rows)
</code></p>

<p>The Nested Loop join takes 456 milliseconds to execute.  This is even worse.
But this is understandable because we have to scan each partition of <code>journal</code>
for each row of <code>q</code>.</p>

<p>Finally, let’s enable RuntimeAppend.</p>

<p><code>sql RuntimeAppend
# EXPLAIN ANALYZE SELECT * FROM q JOIN journal j ON q.dt = j.dt;
                                                                   QUERY PLAN
------------------------------------------------------------------------------------------------------------------------------------------------
 Nested Loop  (cost=0.28..481.67 rows=1000 width=56) (actual time=0.041..9.911 rows=1000 loops=1)
   -&gt;  Seq Scan on q  (cost=0.00..15.00 rows=1000 width=8) (actual time=0.005..0.079 rows=1000 loops=1)
   -&gt;  Custom Scan (RuntimeAppend)  (cost=0.28..0.46 rows=1 width=49) (actual time=0.003..0.003 rows=1 loops=1000)
         -&gt;  Index Scan using journal_330_dt_idx on journal_330 j  (cost=0.28..0.46 rows=1 width=49) (actual time=0.003..0.003 rows=1 loops=5)
               Index Cond: (dt = q.dt)
         -&gt;  Index Scan using journal_121_dt_idx on journal_121 j  (cost=0.28..0.46 rows=1 width=49) (actual time=0.004..0.004 rows=1 loops=1)
               Index Cond: (dt = q.dt)
         -&gt;  Index Scan using journal_37_dt_idx on journal_37 j  (cost=0.28..0.46 rows=1 width=49) (actual time=0.003..0.003 rows=1 loops=4)
               Index Cond: (dt = q.dt)
................................................................................................................................................
         -&gt;  Index Scan using journal_355_dt_idx on journal_355 j  (cost=0.28..0.46 rows=1 width=49) (actual time=0.003..0.003 rows=1 loops=1)
               Index Cond: (dt = q.dt)
 Planning time: 30.775 ms
 Execution time: 8.615 ms
(687 rows)
</code></p>

<p>The Nested Loop join with RuntimeAppend takes only about 9 milliseconds
to execute!  Such fast execution is possible thanks to RuntimeAppend scans only
one relevant partition of <code>journal</code> for each row of <code>q</code>.</p>

<p>Nevertheless, all the partitions are present in plan and planning time is still
quite high.  This relatively high planning time could be not so significant
for prepared statements or long OLAP queries.</p>

<p>However, long planning time appears to be not the only problem.  We run a
benchmark when RuntimeAppend node returns just a few rows in prepared statement.
Despite high planning time doesn’t affect prepared statements, TPS was few
time slower than it was without partitioning.  After running perf, we got this
<a href="/images/runtimeappend_flamegraph.svg">flamegraph</a>.  This flamegraph shows that
we spend very significant time for locking and unlocking every partition.
Naturally, locking 365 partitions isn’t using fast-path locking and appears to
be significant overhead.</p>

<p>Thus, we see how huge benefit could runtime partition selection have.  However,
in current design having all the partitions in plan cause high overhead.
Solution could be found in redesigning partition locking.  We are researching
this problem now.  It’s likely this problem can’t be solved in the boundaries
of extension and proper solution requires hacking of PostgreSQL core.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Drawing Graphs Directly in Psql]]></title>
    <link href="http://akorotkov.github.io/blog/2016/06/09/psql-graph/"/>
    <updated>2016-06-09T16:45:00+03:00</updated>
    <id>http://akorotkov.github.io/blog/2016/06/09/psql-graph</id>
    <content type="html"><![CDATA[<p>For people who are actively working with psql, it frequently happens that you
want to draw graph for the table you’re currently seeing.  Typically, it means a
cycle of actions including: exporting data, importing it into graph drawing tool
and drawing graph itself.  It appears that this process could be automated:
graph could be drawn by typing a single command directly in psql.  See an
example on the screenshot below.</p>

<p><img class="no-border center" src="/images/screen-psql-iterm-graph.png" width="689" height="958"></p>

<!--more-->

<p>It might seem like a magic, but actually there is absolutely no magic.  iTerm2
supports <a href="https://www.iterm2.com/documentation-images.html">image inlining</a>
since version 3 which is currently beta.  Thus, if we put image surrounded
with corresponding escape sequences it will appear in the terminal.  From psql
side we need to redirect output to the script which would do it.  We can define
a macro for simplifying this like in <a href="/blog/2015/08/26/psql-gdb-attach/">one of my previous posts</a>.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="err">\</span><span class="k">set</span> <span class="n">graph</span> <span class="err">‘\</span><span class="k">g</span> <span class="o">|</span><span class="n">pg_graph</span><span class="err">’</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>And finally we need a pg_graph script which parses psql output, draws graph and
puts it into stdout.  I <a href="https://gist.github.com/akorotkov/2c7011ac30de27b9c5631f1bf418f0a1">wrote one</a>
using Python and matplotlib.  It recognizes first column as series of X-values
and rest of columns as series of Y-values.  If first column contains only
decimal values it draws a plot chart, otherwise it draws a bar chart.</p>

<p>Thereby, it’s not hard to teach psql to do more things.  Also, we can consider
some improvements to psql including:</p>

<ul>
  <li>Add output format option for <code>\g</code> which would make it easier to parse psql
output from scripts;</li>
  <li>Provide elegant way to pass parameters into psql macro.</li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[PostgreSQL Scalability: Towards Millions TPS]]></title>
    <link href="http://akorotkov.github.io/blog/2016/05/09/scalability-towards-millions-tps/"/>
    <updated>2016-05-09T12:50:00+03:00</updated>
    <id>http://akorotkov.github.io/blog/2016/05/09/scalability-towards-millions-tps</id>
    <content type="html"><![CDATA[<p>PostgreSQL scalability on multicore and multisocket machines became a subject
of optimization long time ago once such machines became widely used.
<a href="http://suckit.blog.hu/2009/09/29/postgresql_history">This blog post</a> shows
brief history of vertical scalability improvements between versions 8.0 and 8.4.
PostgreSQL 9.2 had very noticeable scalability improvement.  Thanks to fast
path locking and other optimizations it becomes possible to achieve
<a href="http://rhaas.blogspot.ru/2012/04/did-i-say-32-cores-how-about-64.html">more than 350 000 TPS in select-only pgbench test</a>.  The latest stable release PostgreSQL 9.5 also
contain significant scalability advancements including LWLock improvement which
allows achieving <a href="http://amitkapila16.blogspot.ru/2015/01/read-scalability-in-postgresql-95.html">about 400 000 TPS in select-only pgbench test</a>.</p>

<p>Postgres Professional company also became involved into scalability
optimization.  In partnership with IBM we researched PostgreSQL scalability on
modern Power8 servers.  The results of this research was published in
<a href="https://habrahabr.ru/company/postgrespro/blog/270827/">popular Russian blog habrahabr</a>
(<a href="https://translate.google.com/translate?sl=ru&amp;tl=en&amp;js=y&amp;prev=_t&amp;hl=ru&amp;ie=UTF-8&amp;u=https%3A%2F%2Fhabrahabr.ru%2Fcompany%2Fpostgrespro%2Fblog%2F270827%2F&amp;edit-text=&amp;act=url">Google translated version</a>).
As brief result of this research we identify two ways to improve PostgreSQL
scalability on Power8:</p>

<ol>
  <li>Implement Pin/UnpinBuffer() using CAS operations instead of
buffer header spinlock;</li>
  <li>Optimize LWLockAttemptLock() in assembly to make fewer loops for changing
lwlock state.</li>
</ol>

<p>The optimization #1 appears to give huge benefit on big Intel servers as well,
while optimization #2 is Power-specific.  After long rounds of optimization,
cleaning and testing #1 was finally
<a href="http://git.postgresql.org/gitweb/?p=postgresql.git;a=commitdiff;h=48354581">committed by Andres Freund</a>.</p>

<p><img class="no-border center 2x" src="/images/scalability.png" width="720" height="576"></p>

<!--more-->

<p>On the graph above, following PostgreSQL versions were compared:</p>

<ol>
  <li>9.5.2 release – peak is 540 000 TPS with 60 clients,</li>
  <li>9.6 master (more precisely <a href="http://git.postgresql.org/gitweb/?p=postgresql.git;a=commitdiff;h=59455018">59455018</a>) – peak is 1 064 000 TPS
with 110 clients,</li>
  <li>9.6 master where all PGXACTs were full cacheline aligned – peak is
1 722 000 TPS with 200 clients.</li>
</ol>

<p>Alignment issues worth some explanation.  Initially, I complained performance
regression introduced by commit <a href="http://git.postgresql.org/gitweb/?p=postgresql.git;a=commitdiff;h=5364b357">5364b357</a> which increases number of
clog buffers.  That was strange by itself, because read-only benchmark shouldn’t
lookup to clog thanks to hint bits.  As expected it appears that clog buffers
don’t really affect read-only performance directly, <a href="http://git.postgresql.org/gitweb/?p=postgresql.git;a=commitdiff;h=5364b357">5364b357</a> just
changed layout of shared memory structures.</p>

<p>It appears that read-only benchmark became very sensitive to layout of shared
memory structures. As result performance has significant variety depending on
shared_buffers, max_connections and other options which influence shared memory
distribution.  When I gave Andres access to that big machine, he very quickly
find a way to take care about performance irregularity:
<a href="http://www.postgresql.org/message-id/20160411214029.ce3fw6zxim5k6a2r@alap3.anarazel.de">make all PGXACTs full cacheline aligned</a>.
Without this patch SnapshotResetXmin() dirties processor cache containing
multiple PGXACTs.  With this patch SnapshotResetXmin() dirties cacheline with
only single PGXACT.  Thus, GetSnapshotData() have much less cache misses.
That was surprising and good lesson for me.  I knew that alignment influence
performance, but I didn’t expect this influence to be so huge. PGXACT cacheline
alignment issue was discovered after feature freeze for 9.6.  That
means it would be subject for 9.7 development.  Nevertheless, 9.6 have very
noticeable scalability improvement.</p>

<p>Therefore, PostgreSQL single instance delivers more than 1 million TPS and one
could say, that PostgreSQL opens a new era of millions TPS.</p>

<p>P.S. I’d like to thank:</p>

<ul>
  <li>Andres Freund, so-author and committer of patch;</li>
  <li>My PostgresPro colleagues: Dmitry Vasilyev who run a lot of benchmarks,
YUriy Zhuravlev who wrote original proof of concept of this patch;</li>
  <li>Dilip Kumar and Robert Haas who helped with testing.</li>
</ul>

]]></content>
  </entry>
  
</feed>
