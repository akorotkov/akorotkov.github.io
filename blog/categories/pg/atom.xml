<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Pg | Alexander Korotkov's blog]]></title>
  <link href="http://akorotkov.github.io/blog/categories/pg/atom.xml" rel="self"/>
  <link href="http://akorotkov.github.io/"/>
  <updated>2016-06-15T15:20:51+03:00</updated>
  <id>http://akorotkov.github.io/</id>
  <author>
    <name><![CDATA[Alexander Korotkov]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[RuntimeAppend in Pg_pathman: Achievements and New Challenges]]></title>
    <link href="http://akorotkov.github.io/blog/2016/06/15/pg_pathman-runtime-append/"/>
    <updated>2016-06-15T15:00:00+03:00</updated>
    <id>http://akorotkov.github.io/blog/2016/06/15/pg_pathman-runtime-append</id>
    <content type="html"><![CDATA[<p>Dealing with partitioned tables we can’t always select relevant partitions
during query planning.  Naturally, during query planning you can’t know values
which come from subquery or outer part of nested loop join.  Nevertheless, it
would be ridiculous to scan all the partitions in such cases.</p>

<p>This is why my Postgres Professional colleague Dmitry Ivanov developed a
new custom executor node for pg_pathman: RuntimeAppend.  This node behaves
like regular Append node: it contains set of children Nodes which should be
appended.  However, RuntimeAppend have one distinction: each run it selects
only relevant children to append basing on parameter values.</p>

<!--more-->

<p>Let’s consider example: join of <code>journal</code> table which contains row per each
30 seconds of year partitioned by day, and <code>q</code> table which refers 1000 random
rows of <code>journal</code> table.  Without RuntimeAppend optimizer selects Hash Join
plan.</p>

<p><code>sql Regular Append: Hash Join
# EXPLAIN ANALYZE SELECT * FROM q JOIN journal j ON q.dt = j.dt;
                                                          QUERY PLAN
-------------------------------------------------------------------------------------------------------------------------------
 Hash Join  (cost=27.50..25442.51 rows=1000 width=56) (actual time=0.479..252.506 rows=1000 loops=1)
   Hash Cond: (j.dt = q.dt)
   -&gt;  Append  (cost=0.00..21463.01 rows=1051201 width=49) (actual time=0.005..152.258 rows=1051201 loops=1)
         -&gt;  Seq Scan on journal_1 j  (cost=0.00..58.80 rows=2880 width=49) (actual time=0.004..0.247 rows=2880 loops=1)
         -&gt;  Seq Scan on journal_2 j_1  (cost=0.00..58.80 rows=2880 width=49) (actual time=0.001..0.208 rows=2880 loops=1)
         -&gt;  Seq Scan on journal_3 j_2  (cost=0.00..58.80 rows=2880 width=49) (actual time=0.001..0.197 rows=2880 loops=1)
...............................................................................................................................
         -&gt;  Seq Scan on journal_366 j_365  (cost=0.00..1.01 rows=1 width=49) (actual time=0.001..0.001 rows=1 loops=1)
   -&gt;  Hash  (cost=15.00..15.00 rows=1000 width=8) (actual time=0.185..0.185 rows=1000 loops=1)
         Buckets: 1024  Batches: 1  Memory Usage: 48kB
         -&gt;  Seq Scan on q  (cost=0.00..15.00 rows=1000 width=8) (actual time=0.003..0.074 rows=1000 loops=1)
 Planning time: 29.262 ms
 Execution time: 256.337 ms
(374 rows)
</code></p>

<p>The Hash Join execution takes 256 milliseconds for execution and 29 milliseconds
for planning.  Relatively high planning time is expected because all the
partitions are present in plan.  It’s surprising that optimizer didn’t select
Nested Loop join.  Let’s force it to do so by <code>enable_hashjoin = off</code> and
<code>enable_mergejoin = off</code>.</p>

<p><code>sql Regular Append: Nested Loop
# EXPLAIN ANALYZE SELECT * FROM q JOIN journal j ON q.dt = j.dt;
                                                                      QUERY PLAN
------------------------------------------------------------------------------------------------------------------------------------------------------
 Nested Loop  (cost=0.28..170817.00 rows=1000 width=56) (actual time=1.091..452.658 rows=1000 loops=1)
   -&gt;  Seq Scan on q  (cost=0.00..15.00 rows=1000 width=8) (actual time=0.006..0.158 rows=1000 loops=1)
   -&gt;  Append  (cost=0.28..167.14 rows=366 width=49) (actual time=0.218..0.438 rows=1 loops=1000)
         -&gt;  Index Scan using journal_1_dt_idx on journal_1 j  (cost=0.28..0.46 rows=1 width=49) (actual time=0.001..0.001 rows=0 loops=1000)
               Index Cond: (dt = q.dt)
         -&gt;  Index Scan using journal_2_dt_idx on journal_2 j_1  (cost=0.28..0.46 rows=1 width=49) (actual time=0.001..0.001 rows=0 loops=1000)
               Index Cond: (dt = q.dt)
         -&gt;  Index Scan using journal_3_dt_idx on journal_3 j_2  (cost=0.28..0.46 rows=1 width=49) (actual time=0.001..0.001 rows=0 loops=1000)
               Index Cond: (dt = q.dt)
......................................................................................................................................................
         -&gt;  Index Scan using journal_366_dt_idx on journal_366 j_365  (cost=0.12..0.15 rows=1 width=49) (actual time=0.001..0.001 rows=0 loops=1000)
               Index Cond: (dt = q.dt)
 Planning time: 29.922 ms
 Execution time: 456.140 ms
(737 rows)
</code></p>

<p>The Nested Loop join takes 456 milliseconds to execute.  This is even worse.
But this is understandable because we have to scan each partition of <code>journal</code>
for each row of <code>q</code>.</p>

<p>Finally, let’s enable RuntimeAppend.</p>

<p><code>sql RuntimeAppend
# EXPLAIN ANALYZE SELECT * FROM q JOIN journal j ON q.dt = j.dt;
                                                                   QUERY PLAN
------------------------------------------------------------------------------------------------------------------------------------------------
 Nested Loop  (cost=0.28..481.67 rows=1000 width=56) (actual time=0.041..9.911 rows=1000 loops=1)
   -&gt;  Seq Scan on q  (cost=0.00..15.00 rows=1000 width=8) (actual time=0.005..0.079 rows=1000 loops=1)
   -&gt;  Custom Scan (RuntimeAppend)  (cost=0.28..0.46 rows=1 width=49) (actual time=0.003..0.003 rows=1 loops=1000)
         -&gt;  Index Scan using journal_330_dt_idx on journal_330 j  (cost=0.28..0.46 rows=1 width=49) (actual time=0.003..0.003 rows=1 loops=5)
               Index Cond: (dt = q.dt)
         -&gt;  Index Scan using journal_121_dt_idx on journal_121 j  (cost=0.28..0.46 rows=1 width=49) (actual time=0.004..0.004 rows=1 loops=1)
               Index Cond: (dt = q.dt)
         -&gt;  Index Scan using journal_37_dt_idx on journal_37 j  (cost=0.28..0.46 rows=1 width=49) (actual time=0.003..0.003 rows=1 loops=4)
               Index Cond: (dt = q.dt)
................................................................................................................................................
         -&gt;  Index Scan using journal_355_dt_idx on journal_355 j  (cost=0.28..0.46 rows=1 width=49) (actual time=0.003..0.003 rows=1 loops=1)
               Index Cond: (dt = q.dt)
 Planning time: 30.775 ms
 Execution time: 8.615 ms
(687 rows)
</code></p>

<p>The Nested Loop join with RuntimeAppend takes only about 9 milliseconds
to execute!  Such fast execution is possible thanks to RuntimeAppend scans only
one relevant partition of <code>journal</code> for each row of <code>q</code>.</p>

<p>Nevertheless, all the partitions are present in plan and planning time is still
quite high.  This relatively high planning time could be not so significant
for prepared statements or long OLAP queries.</p>

<p>However, long planning time appears to be not the only problem.  We run a
benchmark when RuntimeAppend node returns just a few rows in prepared statement.
Despite high planning time doesn’t affect prepared statements, TPS was few
time slower than it was without partitioning.  After running perf, we got this
<a href="/images/runtimeappend_flamegraph.svg">flamegraph</a>.  This flamegraph shows that
we spend very significant time for locking and unlocking every partition.
Naturally, locking 365 partitions isn’t using fast-path locking and appears to
be significant overhead.</p>

<p>Thus, we see how huge benefit could runtime partition selection have.  However,
in current design having all the partitions in plan cause high overhead.
Solution could be found in redesigning partition locking.  We are researching
this problem now.  It’s likely this problem can’t be solved in the boundaries
of extension and proper solution requires hacking of PostgreSQL core.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Drawing Graphs Directly in Psql]]></title>
    <link href="http://akorotkov.github.io/blog/2016/06/09/psql-graph/"/>
    <updated>2016-06-09T16:45:00+03:00</updated>
    <id>http://akorotkov.github.io/blog/2016/06/09/psql-graph</id>
    <content type="html"><![CDATA[<p>For people who are actively working with psql, it frequently happens that you
want to draw graph for the table you’re currently seeing.  Typically, it means a
cycle of actions including: exporting data, importing it into graph drawing tool
and drawing graph itself.  It appears that this process could be automated:
graph could be drawn by typing a single command directly in psql.  See an
example on the screenshot below.</p>

<p><img class="no-border center" src="/images/screen-psql-iterm-graph.png" width="689" height="958"></p>

<!--more-->

<p>It might seem like a magic, but actually there is absolutely no magic.  iTerm2
supports <a href="https://www.iterm2.com/documentation-images.html">image inlining</a>
since version 3 which is currently beta.  Thus, if we put image surrounded
with corresponding escape sequences it will appear in the terminal.  From psql
side we need to redirect output to the script which would do it.  We can define
a macro for simplifying this like in <a href="/blog/2015/08/26/psql-gdb-attach/">one of my previous posts</a>.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="err">\</span><span class="k">set</span> <span class="n">graph</span> <span class="err">‘\</span><span class="k">g</span> <span class="o">|</span><span class="n">pg_graph</span><span class="err">’</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>And finally we need a pg_graph script which parses psql output, draws graph and
puts it into stdout.  I <a href="https://gist.github.com/akorotkov/2c7011ac30de27b9c5631f1bf418f0a1">wrote one</a>
using Python and matplotlib.  It recognizes first column as series of X-values
and rest of columns as series of Y-values.  If first column contains only
decimal values it draws a plot chart, otherwise it draws a bar chart.</p>

<p>Thereby, it’s not hard to teach psql to do more things.  Also, we can consider
some improvements to psql including:</p>

<ul>
  <li>Add output format option for <code>\g</code> which would make it easier to parse psql
output from scripts;</li>
  <li>Provide elegant way to pass parameters into psql macro.</li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[PostgreSQL Scalability: Towards Millions TPS]]></title>
    <link href="http://akorotkov.github.io/blog/2016/05/09/scalability-towards-millions-tps/"/>
    <updated>2016-05-09T12:50:00+03:00</updated>
    <id>http://akorotkov.github.io/blog/2016/05/09/scalability-towards-millions-tps</id>
    <content type="html"><![CDATA[<p>PostgreSQL scalability on multicore and multisocket machines became a subject
of optimization long time ago once such machines became widely used.
<a href="http://suckit.blog.hu/2009/09/29/postgresql_history">This blog post</a> shows
brief history of vertical scalability improvements between versions 8.0 and 8.4.
PostgreSQL 9.2 had very noticeable scalability improvement.  Thanks to fast
path locking and other optimizations it becomes possible to achieve
<a href="http://rhaas.blogspot.ru/2012/04/did-i-say-32-cores-how-about-64.html">more than 350 000 TPS in select-only pgbench test</a>.  The latest stable release PostgreSQL 9.5 also
contain significant scalability advancements including LWLock improvement which
allows achieving <a href="http://amitkapila16.blogspot.ru/2015/01/read-scalability-in-postgresql-95.html">about 400 000 TPS in select-only pgbench test</a>.</p>

<p>Postgres Professional company also became involved into scalability
optimization.  In partnership with IBM we researched PostgreSQL scalability on
modern Power8 servers.  The results of this research was published in
<a href="https://habrahabr.ru/company/postgrespro/blog/270827/">popular Russian blog habrahabr</a>
(<a href="https://translate.google.com/translate?sl=ru&amp;tl=en&amp;js=y&amp;prev=_t&amp;hl=ru&amp;ie=UTF-8&amp;u=https%3A%2F%2Fhabrahabr.ru%2Fcompany%2Fpostgrespro%2Fblog%2F270827%2F&amp;edit-text=&amp;act=url">Google translated version</a>).
As brief result of this research we identify two ways to improve PostgreSQL
scalability on Power8:</p>

<ol>
  <li>Implement Pin/UnpinBuffer() using CAS operations instead of
buffer header spinlock;</li>
  <li>Optimize LWLockAttemptLock() in assembly to make fewer loops for changing
lwlock state.</li>
</ol>

<p>The optimization #1 appears to give huge benefit on big Intel servers as well,
while optimization #2 is Power-specific.  After long rounds of optimization,
cleaning and testing #1 was finally
<a href="http://git.postgresql.org/gitweb/?p=postgresql.git;a=commitdiff;h=48354581">committed by Andres Freund</a>.</p>

<p><img class="no-border center 2x" src="/images/scalability.png" width="720" height="576"></p>

<!--more-->

<p>On the graph above, following PostgreSQL versions were compared:</p>

<ol>
  <li>9.5.2 release – peak is 540 000 TPS with 60 clients,</li>
  <li>9.6 master (more precisely <a href="http://git.postgresql.org/gitweb/?p=postgresql.git;a=commitdiff;h=59455018">59455018</a>) – peak is 1 064 000 TPS
with 110 clients,</li>
  <li>9.6 master where all PGXACTs were full cacheline aligned – peak is
1 722 000 TPS with 200 clients.</li>
</ol>

<p>Alignment issues worth some explanation.  Initially, I complained performance
regression introduced by commit <a href="http://git.postgresql.org/gitweb/?p=postgresql.git;a=commitdiff;h=5364b357">5364b357</a> which increases number of
clog buffers.  That was strange by itself, because read-only benchmark shouldn’t
lookup to clog thanks to hint bits.  As expected it appears that clog buffers
don’t really affect read-only performance directly, <a href="http://git.postgresql.org/gitweb/?p=postgresql.git;a=commitdiff;h=5364b357">5364b357</a> just
changed layout of shared memory structures.</p>

<p>It appears that read-only benchmark became very sensitive to layout of shared
memory structures. As result performance has significant variety depending on
shared_buffers, max_connections and other options which influence shared memory
distribution.  When I gave Andres access to that big machine, he very quickly
find a way to take care about performance irregularity:
<a href="http://www.postgresql.org/message-id/20160411214029.ce3fw6zxim5k6a2r@alap3.anarazel.de">make all PGXACTs full cacheline aligned</a>.
Without this patch SnapshotResetXmin() dirties processor cache containing
multiple PGXACTs.  With this patch SnapshotResetXmin() dirties cacheline with
only single PGXACT.  Thus, GetSnapshotData() have much less cache misses.
That was surprising and good lesson for me.  I knew that alignment influence
performance, but I didn’t expect this influence to be so huge. PGXACT cacheline
alignment issue was discovered after feature freeze for 9.6.  That
means it would be subject for 9.7 development.  Nevertheless, 9.6 have very
noticeable scalability improvement.</p>

<p>Therefore, PostgreSQL single instance delivers more than 1 million TPS and one
could say, that PostgreSQL opens a new era of millions TPS.</p>

<p>P.S. I’d like to thank:</p>

<ul>
  <li>Andres Freund, so-author and committer of patch;</li>
  <li>My PostgresPro colleagues: Dmitry Vasilyev who run a lot of benchmarks,
YUriy Zhuravlev who wrote original proof of concept of this patch;</li>
  <li>Dilip Kumar and Robert Haas who helped with testing.</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Extensible Access Methods Are Committed to 9.6]]></title>
    <link href="http://akorotkov.github.io/blog/2016/04/06/extensible-access-methods/"/>
    <updated>2016-04-06T15:26:00+03:00</updated>
    <id>http://akorotkov.github.io/blog/2016/04/06/extensible-access-methods</id>
    <content type="html"><![CDATA[<p>PostgreSQL 9.6 receives suitable support of extensible index access methods.
And that’s good news because Postgres was initially designed to support it.</p>

<blockquote>
  <p>“It is imperative that a user be able to construct new access methods to 
provide efficient access to instances of nontraditional base types”</p>

  <p>Michael Stonebraker, Jeff Anton, Michael Hirohama.
Extendability in POSTGRES , IEEE Data Eng. Bull. 10 (2) pp.16-23, 1987</p>
</blockquote>

<p>That was a huge work which consists of multiple steps.</p>

<!--more-->

<ol>
  <li>Rework access method interface so that access method internals are hidden
from SQL level to C level.  Besides help for custom access methods support,
this refactoring is good by itself.<br />
<a href="http://git.postgresql.org/gitweb/?p=postgresql.git;a=commitdiff;h=65c5fcd3">Committed</a> by Tom Lane.</li>
  <li><code>CREATE ACCESS METHOD</code> command which provides legal way for insertion into
pg_am with support of dependencies and pg_dump/pg_restore.
<a href="http://git.postgresql.org/gitweb/?p=postgresql.git;a=commitdiff;h=473b9328">Committed</a> by Alvaro Herrera.</li>
  <li>Generic WAL interface which provides custom access methods the way to be
WAL-logged.  Each built-in access method has its own type of WAL records.
But custom access method shouldn’t because it could affect reliability.
Generic WAL records represent difference between pages in general way as
result of per-byte comparison of original and modified images of the page.
For sure, it is not as efficient as own type of WAL records, but there is
no choice under restrictions we have.
<a href="http://git.postgresql.org/gitweb/?p=postgresql.git;a=commitdiff;h=65578341">Committed</a> by Teodor Sigaev.</li>
  <li>Bloom contrib module which is example of custom index access method which
uses generic WAL interface.  This contrib is essential for testing
infrastructure described above.  Also, this access method could be useful by
itself.
<a href="http://git.postgresql.org/gitweb/?p=postgresql.git;a=commitdiff;h=9ee014fc">Committed</a> by Teodor Sigaev.</li>
</ol>

<p>I am very thankful for the efforts of committers and reviewers who make it
possible to include these features into PostgreSQL.</p>

<p>However, end users don’t really care about this infrastructure.  They do care
about features we can provide on the base of this infrastructure.  Actually,
we would be able to have index access methods which are:</p>

<ul>
  <li>Too hard to add to PostgreSQL core.  For instance, we presented
<a href="https://wiki.postgresql.org/images/2/25/Full-text_search_in_PostgreSQL_in_milliseconds-extended-version.pdf">fast FTS</a>
in 2012.  We have 2 of 4 GIN features committed to core.  And it seems to be
very long way to have rest of features in core.  But since 9.6 we would
provide it as an extension.</li>
  <li>Not patent free.  There are some interesting data structures which are
covered by patents (Fractal Tree index, for example).  This is why they
couldn’t be added to PostgreSQL core.  Since 9.6, they could be provided
without fork.</li>
</ul>

<p>Also, I consider this work as an approach (together with FDW) to pluggable
storage engines.  I will speak about this during my
<a href="http://www.pgcon.org/2016/schedule/events/920.en.html">talk at PGCon 2016</a>.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Monitoring Wait Events in PostgreSQL 9.6]]></title>
    <link href="http://akorotkov.github.io/blog/2016/03/25/wait_monitoring_9_6/"/>
    <updated>2016-03-25T18:00:00+03:00</updated>
    <id>http://akorotkov.github.io/blog/2016/03/25/wait_monitoring_9_6</id>
    <content type="html"><![CDATA[<p>Recently Robert Haas has <a href="http://git.postgresql.org/gitweb/?p=postgresql.git;a=commitdiff;h=53be0b1a">committed</a> a patch which allows
seeing some more detailed information about current wait event of the process.
In particular, user will be able to see if process is waiting for heavyweight
lock, lightweight lock (either individual or tranche) or buffer pin.  The full
list of wait events is available in the
<a href="http://www.postgresql.org/docs/devel/static/monitoring-stats.html#WAIT-EVENT-TABLE">documentation</a>.
Hopefully, it will be more wait events in further releases.</p>

<p>It’s nice to see current wait event of the process, but just one snapshot is
not very descriptive and definitely not enough to do any conclusion.  But
we can use sampling for collecting suitable statistics.  This is why I’d like
to present <a href="https://github.com/postgrespro/pg_wait_sampling">pg_wait_sampling</a>
which automates gathering sampling statistics of wait events.  pg_wait_sampling
enables you to gather statistics for graphs like the one below.</p>

<p><img class="no-border" src="/images/wait_monitoring.png" width="629" height="638"></p>

<!--more-->

<p>Let me explain you how did I draw this graph. pg_wait_sampling samples wait
events into two destinations: history and profile.  History is an in-memory
ring buffer and profile is an in-memory hash table with accumulated statistics.
We’re going to use the second one to see insensitivity of wait events over time
periods.</p>

<p>At first, let’s create table for accumulated statistics.  I’m doing these
experiments on my laptop, and for the simplicity this table will live in the
instance under monitoring.  But note, that such table could live on the another
server.  I’d even say it’s preferable to place such data to another server.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">profile_log</span> <span class="p">(</span>
</span><span class='line'>    <span class="n">ts</span>         <span class="k">timestamp</span><span class="p">,</span>
</span><span class='line'>    <span class="n">event_type</span> <span class="nb">text</span><span class="p">,</span>
</span><span class='line'>    <span class="n">event</span>      <span class="nb">text</span><span class="p">,</span>
</span><span class='line'>    <span class="k">count</span>      <span class="nb">int8</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>Secondly, I wrote a function to copy data from pg_wait_sampling_profile view to
profile_log table and clean profile data.  This function returns number of
rows inserted into profile_log table.  Also, this function discards pid number
and groups data by wait event.  And this is not necessary needed to be so.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">CREATE</span> <span class="k">OR</span> <span class="k">REPLACE</span> <span class="k">FUNCTION</span> <span class="n">write_profile_log</span><span class="p">()</span> <span class="k">RETURNS</span> <span class="nb">integer</span> <span class="k">AS</span> <span class="o">&lt;</span><span class="n">script</span> <span class="k">type</span><span class="o">=</span><span class="ss">&quot;math/tex&quot;</span><span class="o">&gt;</span><span class="k">DECLARE</span>
</span><span class='line'>    <span class="k">result</span> <span class="nb">integer</span><span class="p">;</span>
</span><span class='line'><span class="k">BEGIN</span>
</span><span class='line'>    <span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">profile_log</span>
</span><span class='line'>        <span class="k">SELECT</span> <span class="k">current_timestamp</span><span class="p">,</span> <span class="n">event_type</span><span class="p">,</span> <span class="n">event</span><span class="p">,</span> <span class="k">SUM</span><span class="p">(</span><span class="k">count</span><span class="p">)</span>
</span><span class='line'>        <span class="k">FROM</span> <span class="n">pg_wait_sampling_profile</span>
</span><span class='line'>        <span class="k">WHERE</span> <span class="n">event</span> <span class="k">IS</span> <span class="k">NOT</span> <span class="k">NULL</span>
</span><span class='line'>        <span class="k">GROUP</span> <span class="k">BY</span> <span class="n">event_type</span><span class="p">,</span> <span class="n">event</span><span class="p">;</span>
</span><span class='line'>    <span class="k">GET</span> <span class="k">DIAGNOSTICS</span> <span class="k">result</span> <span class="o">=</span> <span class="k">ROW_COUNT</span><span class="p">;</span>
</span><span class='line'>    <span class="n">PERFORM</span> <span class="n">pg_wait_sampling_reset_profile</span><span class="p">();</span>
</span><span class='line'>    <span class="k">RETURN</span> <span class="k">result</span><span class="p">;</span>
</span><span class='line'><span class="k">END</span><span class="o">&lt;/</span><span class="n">script</span><span class="o">&gt;</span>
</span><span class='line'><span class="k">LANGUAGE</span> <span class="err">‘</span><span class="n">plpgsql</span><span class="err">’</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>And then I run psql session where setup watch of this function.  Monitoring of
our system is started.  For real usage it’s better to schedule this command
using cron or something.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="n">smagen</span><span class="o">@</span><span class="n">postgres</span><span class="o">=#</span> <span class="k">SELECT</span> <span class="n">write_profile_log</span><span class="p">();</span>
</span><span class='line'> <span class="n">write_profile_log</span>
</span><span class='line'><span class="err">——————</span><span class="o">-</span>
</span><span class='line'>                 <span class="mi">0</span>
</span><span class='line'><span class="p">(</span><span class="mi">1</span> <span class="k">row</span><span class="p">)</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">smagen</span><span class="o">@</span><span class="n">postgres</span><span class="o">=#</span> <span class="err">\</span><span class="n">watch</span> <span class="mi">10</span>
</span><span class='line'><span class="n">Fri</span> <span class="n">Mar</span> <span class="mi">25</span> <span class="mi">14</span><span class="p">:</span><span class="mi">03</span><span class="p">:</span><span class="mi">09</span> <span class="mi">2016</span> <span class="p">(</span><span class="k">every</span> <span class="mi">10</span><span class="n">s</span><span class="p">)</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">h2</span> <span class="n">id</span><span class="o">=</span><span class="ss">&quot;writeprofilelog&quot;</span><span class="o">&gt;</span><span class="n">write_profile_log</span><span class="o">&lt;/</span><span class="n">h2</span><span class="o">&gt;</span>
</span><span class='line'><span class="o">&lt;</span><span class="n">pre</span><span class="o">&gt;&lt;</span><span class="n">code</span><span class="o">&gt;</span>             <span class="mi">0</span> <span class="p">(</span><span class="mi">1</span> <span class="k">row</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>
</code></pre>

<p>We can see that write_profile_log returns 0.  That means we didn’t insert
anything to profile_log.  And this is right because system is not under load
now.  Let us create some load using pgbench.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>pgbench -i -s <span class="m">10</span> postgres
</span><span class='line'><span class="nv">$ </span>pgbench -j <span class="m">10</span> -c <span class="m">10</span> -M prepared -T <span class="m">60</span> postgres
</span></code></pre></td></tr></table></div></figure></p>

<p>In the parallel session we can see that write_profile_log starts to insert some
data to profile_log table.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="n">Fri</span> <span class="n">Mar</span> <span class="mi">25</span> <span class="mi">14</span><span class="p">:</span><span class="mi">04</span><span class="p">:</span><span class="mi">19</span> <span class="mi">2016</span> <span class="p">(</span><span class="k">every</span> <span class="mi">10</span><span class="n">s</span><span class="p">)</span>
</span><span class='line'> <span class="n">write_profile_log</span>
</span><span class='line'><span class="err">——————</span><span class="o">-</span>
</span><span class='line'>                 <span class="mi">9</span>
</span><span class='line'><span class="p">(</span><span class="mi">1</span> <span class="k">row</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>Finally, let’s examine the profile_log table.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'> <span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">profile_log</span><span class="p">;</span>
</span><span class='line'>             <span class="n">ts</span>             <span class="o">|</span>  <span class="n">event_type</span>   <span class="o">|</span>       <span class="n">event</span>       <span class="o">|</span> <span class="k">count</span>
</span><span class='line'><span class="err">—————————</span><span class="o">-+</span><span class="err">—————</span><span class="o">+</span><span class="err">——————</span><span class="o">-+</span><span class="err">——</span><span class="o">-</span>
</span><span class='line'> <span class="mi">2016</span><span class="o">-</span><span class="mi">03</span><span class="o">-</span><span class="mi">25</span> <span class="mi">14</span><span class="p">:</span><span class="mi">03</span><span class="p">:</span><span class="mi">19</span><span class="p">.</span><span class="mi">286394</span> <span class="o">|</span> <span class="k">Lock</span>          <span class="o">|</span> <span class="n">tuple</span>             <span class="o">|</span>    <span class="mi">41</span>
</span><span class='line'> <span class="mi">2016</span><span class="o">-</span><span class="mi">03</span><span class="o">-</span><span class="mi">25</span> <span class="mi">14</span><span class="p">:</span><span class="mi">03</span><span class="p">:</span><span class="mi">19</span><span class="p">.</span><span class="mi">286394</span> <span class="o">|</span> <span class="n">LWLockTranche</span> <span class="o">|</span> <span class="n">lock_manager</span>      <span class="o">|</span>     <span class="mi">1</span>
</span><span class='line'> <span class="mi">2016</span><span class="o">-</span><span class="mi">03</span><span class="o">-</span><span class="mi">25</span> <span class="mi">14</span><span class="p">:</span><span class="mi">03</span><span class="p">:</span><span class="mi">19</span><span class="p">.</span><span class="mi">286394</span> <span class="o">|</span> <span class="n">LWLockTranche</span> <span class="o">|</span> <span class="n">buffer_content</span>    <span class="o">|</span>    <span class="mi">68</span>
</span><span class='line'> <span class="mi">2016</span><span class="o">-</span><span class="mi">03</span><span class="o">-</span><span class="mi">25</span> <span class="mi">14</span><span class="p">:</span><span class="mi">03</span><span class="p">:</span><span class="mi">19</span><span class="p">.</span><span class="mi">286394</span> <span class="o">|</span> <span class="n">LWLockTranche</span> <span class="o">|</span> <span class="n">wal_insert</span>        <span class="o">|</span>     <span class="mi">3</span>
</span><span class='line'> <span class="mi">2016</span><span class="o">-</span><span class="mi">03</span><span class="o">-</span><span class="mi">25</span> <span class="mi">14</span><span class="p">:</span><span class="mi">03</span><span class="p">:</span><span class="mi">19</span><span class="p">.</span><span class="mi">286394</span> <span class="o">|</span> <span class="n">LWLockNamed</span>   <span class="o">|</span> <span class="n">WALWriteLock</span>      <span class="o">|</span>    <span class="mi">68</span>
</span><span class='line'> <span class="mi">2016</span><span class="o">-</span><span class="mi">03</span><span class="o">-</span><span class="mi">25</span> <span class="mi">14</span><span class="p">:</span><span class="mi">03</span><span class="p">:</span><span class="mi">19</span><span class="p">.</span><span class="mi">286394</span> <span class="o">|</span> <span class="k">Lock</span>          <span class="o">|</span> <span class="n">transactionid</span>     <span class="o">|</span>   <span class="mi">331</span>
</span><span class='line'> <span class="mi">2016</span><span class="o">-</span><span class="mi">03</span><span class="o">-</span><span class="mi">25</span> <span class="mi">14</span><span class="p">:</span><span class="mi">03</span><span class="p">:</span><span class="mi">19</span><span class="p">.</span><span class="mi">286394</span> <span class="o">|</span> <span class="n">LWLockNamed</span>   <span class="o">|</span> <span class="n">ProcArrayLock</span>     <span class="o">|</span>     <span class="mi">8</span>
</span><span class='line'> <span class="mi">2016</span><span class="o">-</span><span class="mi">03</span><span class="o">-</span><span class="mi">25</span> <span class="mi">14</span><span class="p">:</span><span class="mi">03</span><span class="p">:</span><span class="mi">19</span><span class="p">.</span><span class="mi">286394</span> <span class="o">|</span> <span class="n">LWLockNamed</span>   <span class="o">|</span> <span class="n">WALBufMappingLock</span> <span class="o">|</span>     <span class="mi">5</span>
</span><span class='line'> <span class="mi">2016</span><span class="o">-</span><span class="mi">03</span><span class="o">-</span><span class="mi">25</span> <span class="mi">14</span><span class="p">:</span><span class="mi">03</span><span class="p">:</span><span class="mi">19</span><span class="p">.</span><span class="mi">286394</span> <span class="o">|</span> <span class="n">LWLockNamed</span>   <span class="o">|</span> <span class="n">CLogControlLock</span>   <span class="o">|</span>     <span class="mi">1</span>
</span><span class='line'><span class="err">………………………………………………………………</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>How to interpret these data?  In the first row we can see that count for tuple
lock for 14:03:19 is 41.  The pg_wait_sampling collector samples wait event
every 10 ms while write_profile_log function writes snapshot of profile every
10 s.  Thus, it was 1000 samples during this period.  Taking into account that
it was 10 backends serving pgbench, we can read the first row as “from 14:03:09
to 14:03:19 backends spend about 0.41% of time in waiting for tuple lock”.</p>

<p>That’s it.  This blog post shows how you can setup a wait event monitoring
of your database using
<a href="https://github.com/postgrespro/pg_wait_sampling">pg_wait_sampling</a>
extension with PostgreSQL 9.6.  This example was given just for introduction and
it is simplified in many ways.  But experienced DBAs would easily adopt it for
their setups.</p>

<p>P.S. Every monitoring has some overhead.  Overhead of wait monitoring was
subject of hot debates in mailing lists.  This is why features like exposing
wait events parameters and measuring each wait event individually are not yet
in 9.6.  But sampling also has overhead.  I hope pg_wait_sampling would be a
start point to show on comparison that other approaches are not that bad, and
finally we would have something way more advanced for 9.7.</p>

]]></content>
  </entry>
  
</feed>
